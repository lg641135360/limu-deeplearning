* 数据操作 
  * N维数组 机器学习和神经网络主要数据结构
    * 0-d （标量）一个类别
    * 1-d（向量） 一个特征向量
    * 2-d（矩阵） 一个样本-特征矩阵
    * 3-d（宽x高x通道） RGB图片
    * 4-d（批量大小x宽x高x通道） 一个批量RGB图片
    * 5-d（批量大小x时间x宽x高x通道）一个视频批量
  * 创建数组需要
    * 形状：例如3x4矩阵
    * 元素数据类型：例如32位浮点数
    * 元素值：例如全0/随机数
  * 访问元素
    * 一个元素  [1,2]
    * 一行  [1,:]    
      * ：代表将该维度所有元素访问出来
    * 一列  [:,1]
    * 子区域  [1:3,1:] 
      * 1:3 == [1,3) 前闭后开
      * 1: 代表拿到1列后所有列
    * 子区域  [::3,::2]
      * 跳着访问，第0行和第三行，列取第0列和第2列

---

#### 数据操作实例

```python
##### //导入torch，被称为PyTorch，但还是导入torch

import torch

// 张量表示一个数值组成的数组，数组可能很多维度

x = torch.arange(12)   // 生成0-11的12个数字组成的数组（向量）

x

x.shape      张量形状

x.numel      张量元素的总数

x=x.reshape(3,4)

x 



// 使用全0、全1、其他常量或从特定分布中随机采样的数字

torch.zeros((2,3,4))     // zeros第一个参数可以是list，也可以用tuple元组，区别是list有序可变，tuple有序不可变，更加安全，一旦初始化就不能再次改变，这里就是生成2个通道的3x4数组

torch.ones((2,3,4))

// 生成特定元素（嵌套列表）

torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]]) 

// 按元素进行算数运算

x=torch.tensor([1.0,2,4,8])

y=torch.tensor([2,2,2,2])

x+y,x-y,x*y,x/y,x ** y   //  求幂运算

torch.exp(x)                   // 指数运算



X = torch.arange(12,dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0,1,4,3],[1,2,3,4],[4,3,2,1]])

torch.cat((X,Y),dim=0),torch.cat((X,Y),dim=1)   // dim=0,横向堆积，dim=1竖向堆积



X == Y 生成bool数组

X.sum()求和

// 广播机制 按元素操作

a = torch.arange(3).reshape((3,1))
b = torch.arange(2).reshape((1,2))
a,b

a+b
tensor([[0, 1],
        [1, 2],
        [2, 3]])
# 两个张量维度要一样（2），这里会自动将维度低的复制成[3,2] 相加
[-1]选择最后一个元素，[1:3]选择第1个和第二个元素（第2行和第3行）从0开始的索引

# 指定索引将元素写入矩阵
X[1,2] = 9
X    # 将[1,2]位置改成9

# 分配内存操作 
before=id(Y)    # 这里的id类似指针操作
Y=Y+X
id(Y) == before  # False
# 原地操作
Z = torch.zeros_like(Y)
print('id(Z):',id(Z))
Z[:] = X+Y
print('id(Z):',id(Z))

# 后续没有重复计算X，直接使用X[:] = X+Y或X+=Y来减少内存开销

# 转换为NumPy张量
A=X.numpy()
B=torch.tensor(A)
type(A),type(B)

# 将大小为1 的张量转换成Python标量
a = torch.tensor([3.5])
a,a.item(),float(a),int(a)
```

