##### 学习过程

> * 人类
>
>   * 结合老师的讲解进行**消化理解 **  ----  **学习**
>   * 做些练习题找到问题并**加强巩固**  ----  **练习**
>   * 通过考试来**检验**学习的最终**效果**  ----  **考试**
>
> * 机器学习
>
>   * **模型拟合**（model fitting）：利用训练数据集（training set）对模型的普通参数进行拟合
>
>   * **模型选择**（model selection）：利用验证数据集（validation set）对模型的超参数进行调整，筛选出性能最好的模型
>   * **模型评价**（model assessment）：利用测试数据集（test set）来估计筛选出的模型在未知数据上的真实性能

###### 模型拟合

* 任务：计算未知参数
  * 重要问题：拟合参数前确定**模型的形式**，或者说到底**要拟合哪些参数**
    * 模型设计
      * 模型的**合理性**很大程度上取决于待解决**问题本身的特征**
        * **无免费午餐定理**
      * 模型的**复杂度**也要和**问题的复杂度**相匹配
        * **奥卡姆剃刀原则**
  * 模型拟合本身只是数学问题

###### “天下没有免费的午餐”

* 任何模型在所有问题上的**性能都是相同的**，其**总误差和模型本身是没有关系**的。
  * 核心前提，也就是**每种问题出现的概率是均等的，每个模型用于解决所有问题时，其平均意义上的性能是一样的**。
    * 模型角度，如果单独拿出一个**特定的模型**来观察的话，这个模型必然会在解决某些问题时**误差较小**，而在解决**另一些问题时误差较大**
    * 问题角度，如果单独拿出一个**特定的问题**来观察的话，必然有某些模型在解决这些问题时具有**较高的精度**，而**另一些模型的精度就没那么理想**

> 如果把**不同模型**看成**一个班级**里的**不同学生**，**不同问题**看成考试时的**不同科目**，NFL 定理说的就是在**这个班里**，**所有学生**期末考试的**总成绩都是一样的**，既然总成绩一样，每一科的平均分自然也是一样的。这一方面说明了每个学生都有偏科，数学好的语文差，语文好的数学差，如果数学语文都好，那么英语肯定更差；另一方面也说明了每个科目的试题都有明显的区分度，数学有高分也有低分，语文有高分也有低分，不会出现哪一科上大家都是 90 分或者大家都是 30 分的情形。

* 重要意义
  * 利用**先验知识**，**具体问题具体分析**
  * 机器学习目标
    * 关于特定问题有针对性的解决方案
  * 模型学习过程中关注**问题本身特点**（**问题的先验知识**）

> 这就像学习数学有学习数学的方法，这套方法用来学习语文未必会有良好的效果，但它只要能够解决数学的问题就已经很有价值了。**脱离问题的实际情况谈论模型优劣是没有意义的，只有让模型的特点和问题的特征相匹配，模型才能发挥最大的作用**。

###### **奥卡姆剃刀**（Occam's Razor）

* 如果有**多种模型**都能够**同等程度地符合同一个问题的观测结果**，那就应该选择其中使用**假设最少的**，也就是**最简单的模型**
* 本质关注点：**模型复杂度**
  * 学到的**模型**应该能够**识别**出数据背后的模式，也就是**数据特征和数据类别**之间的关系
  * **模型过于复杂**时，特征和类别之间的**关系中所有的细枝末节**都被捕捉，**主要的趋势**反而在乱花渐欲迷人眼中**没有得到应有的重视**，这就会导致**过拟合**（overfitting）的发生
  * **模型过于简单**，它不仅**没有能力捕捉细微的相关性**，甚至连**主要趋势本身都没办法抓住**，这样的现象就是**欠拟合**（underfitting）

> ###### 模型复杂度与拟合精度的关系
>
> * 过于**简单的模型**就像给**三五百人一起上大课**，不管听课的学生水平如何参差不齐，**上课的内容都固定不变**，或者**变化很小**。这种教学的**效果一定不好**：**水平高的学生不用听**也会，**水平差的学生听了也不会**，就像**欠拟合的模型在训练集上都没有良好**的表现，更遑论泛化性能了。
> * 过于**复杂的模型**则是**一对一的闭门辅导**，**针对每个学生不同的问题做出不同的解答**，数学不好的补数学，语文不好的补语文。这样**因材施教的教学效果固然优良**，却因为它的**针对性而没法推广**，就像过拟合的模型能够在训练集上表现优异，却因为针对性过强，同样**不具备良好的泛化性能**
>
> ###### 从误差角度看模型复杂度
>
> * 模型误差 == 偏差的平方与方差之和
>   * 偏差（bias）
>     * 模型预测值的期望和真实结果之间的区别，如果偏差为 0，**模型给出的估计**的就是**无偏估计**
>     * 不意味着每个预测值都与真实值吻合
>   * 方差（variance）
>     * 模型**预测值的方差**，也就是**预测值本身的波动程度**，方差**越小**意味着模型**越有效**
>   * 噪声（noise）
>     * **不可约误差**（irreducible error）
>     * 待学习问题本身难度，**不能通过模型训练得到改善**
>
> * 偏差与方差的**折中**
>   * **偏差**来源于模型中的**错误假设**，**过高**就意味着**模型所代表的特征**和**分类结果**之间的**关系是错误**的，对应着**欠拟合现象**
>   * **方差**则来源于模型对**训练数据波动**的**过度敏感**，方差**过高**意味着模型对**数据中的随机噪声**也**进行了建模**，将本**不属于特征 - 分类关系中的随机特性**也纳入到模型之中，对应着**过拟合现象**

###### 理想模型

* **低偏差低方差**的双低模型

###### 一般情况

* **偏差和方差既不会同时较低，也不会同时较高，而是在跷跷板的两端此起彼伏，一个升高另一个就降低。**
* 模型**复杂度越低**，其**偏差也就越高**；模型的**复杂度越高**，其**方差也就越高**
  * 简单模型
    * 斜眼的箭手，射出的箭都在远离靶心的 7 环的某一点附近
  * 复杂模型
    * 心理不稳定的箭手，本来是 9 环水平却一下射出 10 环一下射出 8 环

###### 调整模型复杂度

* 在**偏差 - 方差的折中**中找到**最优解**，使得两者之和所表示的**总误差达到最小值**。这样的模型既能**提取出特征和分类结果之间的关系**，又**不至于放大噪声和干扰的影响**。

