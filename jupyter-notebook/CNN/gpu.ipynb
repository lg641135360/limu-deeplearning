{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116a48f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  9 16:59:26 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.36       Driver Version: 440.36       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 81%   78C    P2   194W / 280W |   2793MiB / 11175MiB |     71%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 37%   63C    P2   189W / 280W |   2377MiB / 11178MiB |     65%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1335      G   /usr/lib/xorg/Xorg                           176MiB |\r\n",
      "|    0      5595      G   /opt/teamviewer/tv_bin/TeamViewer              2MiB |\r\n",
      "|    0      5900      G   compiz                                       199MiB |\r\n",
      "|    0     12819      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "|    0     13850      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "|    0     18986      C   python                                      2395MiB |\r\n",
      "|    1     18986      C   python                                      2365MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0598f4",
   "metadata": {},
   "source": [
    "##### 计算设备\n",
    "所有的深度学习框架\n",
    "默认在cpu上做运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdc1a446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " <torch.cuda.device at 0x7f1fbc22a208>,\n",
       " <torch.cuda.device at 0x7f1fbc22a278>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.device('cpu'),torch.cuda.device('cuda'),torch.cuda.device('cuda:1')\n",
    "# 查看cpu设备、第0个gpu，第1个gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d2a56",
   "metadata": {},
   "source": [
    "#### 查询可用gpu的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6195bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b2634",
   "metadata": {},
   "source": [
    "#### 这两个函数允许我们在请求的GPU不存在的情况下运行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfab3c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cpu'),\n",
       " [device(type='cuda', index=0), device(type='cuda', index=1)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0):  \n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()。\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpus():  \n",
    "    \"\"\"返回所有可用的GPU，如果没有GPU，则返回[cpu(),]。\"\"\"\n",
    "    devices = [\n",
    "        torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [torch.device('cpu')]\n",
    "\n",
    "try_gpu(), try_gpu(10), try_all_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ba8aa",
   "metadata": {},
   "source": [
    "#### 查询张量存在的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6dcc304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13729a00",
   "metadata": {},
   "source": [
    "#### 存储在gpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfac7756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2,3,device=try_gpu())\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e40de1",
   "metadata": {},
   "source": [
    "#### 第二个gpu上创建一个随机张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c593b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0920, 0.4711, 0.3697],\n",
       "        [0.9173, 0.7190, 0.8875]], device='cuda:1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = torch.rand(2,3,device=try_gpu(1))\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8806499f",
   "metadata": {},
   "source": [
    "#### 要计算X+Y，需要决定在那里执行这个操作\n",
    "把放在不同gpu的张量移到一个gpu上执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cbf2086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:0')\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "z = X.cuda(1)\n",
    "print(X)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3207e",
   "metadata": {},
   "source": [
    "#### 现在数据同在一个GPU上（Z和Y都在1号gpu），可以将它们相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23380ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0920, 1.4711, 1.3697],\n",
       "        [1.9173, 1.7190, 1.8875]], device='cuda:1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f808b250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.cuda(1) is z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d278bed",
   "metadata": {},
   "source": [
    "#### 神经网络与GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf8cbf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8964],\n",
       "        [-0.8964]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(3,1))\n",
    "net = net.to(device=try_gpu())   # 移动到gpu上\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29cdb0d",
   "metadata": {},
   "source": [
    "#### 确认模型参数存储在同一个gpu上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69278e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39f26c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
