{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da69868c",
   "metadata": {},
   "source": [
    "#### 层和块\n",
    "回顾多层感知机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3cf356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0290, -0.0548,  0.0060,  0.0044,  0.0147,  0.0257,  0.1951, -0.0426,\n",
       "          0.0341, -0.0172],\n",
       "        [ 0.1010, -0.0769,  0.0766,  0.0194, -0.1755,  0.0256,  0.1011,  0.1187,\n",
       "          0.1113,  0.0254]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# 定义了一些没有参数的函数\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 这里构造一个线性层+激活函数+线性层\n",
    "net = nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "\n",
    "# X是一个随机生成矩阵 2 批量大小 20输入维度\n",
    "X = torch.rand(2,20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be38ca",
   "metadata": {},
   "source": [
    "#### nn.Sequential定义一种特殊的Module\n",
    "Module可以被认为是任何一个层和一神经网络的父类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4428ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义一个与MLP一样的函数\n",
    "class MLP(nn.Module): # 这里是继承Module类，得到一些好用的函数\n",
    "    def __init__(self): # 函数一：定义需要的类和参数\n",
    "        super().__init__() # 调用父类，将需要的内部参数设置好\n",
    "        self.hidden = nn.Linear(20,256) # 将一层存储在类的成员变量中\n",
    "        self.out = nn.Linear(256,10)  # 同理定义输出层\n",
    "    \n",
    "    def forward(self,X):    # 前置函数 定义前向计算的做法\n",
    "        return self.out(F.relu(self.hidden(X))) # 定义输出的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450253f5",
   "metadata": {},
   "source": [
    "#### 实例化多层感知机的各个层，然后每次调用正向传播函数时调用这些层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e770832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0941,  0.1180, -0.0101, -0.3343, -0.1031,  0.1018, -0.0574, -0.1098,\n",
       "          0.2197, -0.1258],\n",
       "        [-0.0589,  0.2010,  0.0047, -0.1954, -0.0508, -0.0389, -0.0332,  0.0156,\n",
       "          0.2268,  0.1484]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP() # 实例化这个类\n",
    "net(X)      # 用X构造，得到输出2x10的矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc46ee",
   "metadata": {},
   "source": [
    "#### 实现顺序块的类\n",
    "与上面类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7380b6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1573, -0.1332,  0.1710, -0.0105,  0.1711,  0.2546,  0.2754,  0.1214,\n",
       "          0.0046, -0.0474],\n",
       "        [ 0.2970, -0.0584,  0.1688, -0.0290,  0.2502,  0.1823,  0.3054,  0.0456,\n",
       "          0.0027, -0.1731]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self,*args): # 接受一个list of arg，每个子类\n",
    "        super().__init__()\n",
    "        for block in args:    # 遍历每一个层\n",
    "            self._modules[block] = block # pytorch定义了_modules容器，放的都是层\n",
    "    \n",
    "    def forward(self,X):\n",
    "        for block in self._modules.values(): # 是有序的，直接就遍历赋值极客\n",
    "            X = block(X)\n",
    "        return X\n",
    "net = MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805e7d9",
   "metadata": {},
   "source": [
    "#### 在正向传播函数中执行代码\n",
    "继承，可以做成更多灵活操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee802b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1460, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 修改函数，增加需要的计算\n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 增加一个不参与计算的权重层\n",
    "        self.rand_weight = torch.rand((20,20),requires_grad=False)\n",
    "        self.linear = nn.Linear(20,20)\n",
    "    \n",
    "    def forward(self,X):                  # 将X放进来\n",
    "        X = self.linear(X)                # 先过一个线性层\n",
    "        X = F.relu(torch.mm(X,self.rand_weight) +1 )   # 做一个矩阵乘法，然后偏执\n",
    "        X = self.linear(X)\n",
    "        while(X.abs().sum() > 1):   # 当绝对值求和大于1的时候，就循环除2\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "\n",
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee40d8f",
   "metadata": {},
   "source": [
    "#### 混合搭配各种组合块的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c2c0424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1030, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20,64),nn.ReLU(),\n",
    "                                nn.Linear(64,32),nn.ReLU())\n",
    "        self.linear = nn.Linear(32,16)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        return self.linear(self.net(X))\n",
    "chimera = nn.Sequential(NestMLP(),nn.Linear(16,20),FixedHiddenMLP())\n",
    "chimera(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620519f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5606fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
